{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQXajFvnASK62w1m2xMYat",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyPatel1311/Quantum-Computing/blob/main/Auto-Tune%20Charge%20State%20for%20Quantum%20Dots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5X3o4ju1bha"
      },
      "outputs": [],
      "source": [
        "!git clone https://gitlab.com/QMAI/mlqe_2023_edx.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import scipy as sp\n",
        "from scipy.special import softmax\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import glob\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "u28gMG0k1em3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "9U1pNv5A1rRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "cdEAGLdi2ZPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('mlqe_2023_edx/week3/dataset/csds.npy', 'rb') as f:\n",
        "    data = np.load(f)\n",
        "with open('mlqe_2023_edx/week3/dataset/labels.npy', 'rb') as f:\n",
        "    labels = np.load(f)"
      ],
      "metadata": {
        "id": "A6lxA7Dy2rMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "Laz9byNj4CAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_data = 2000\n",
        "data = data[:number_of_data]\n",
        "labels = labels[:number_of_data]"
      ],
      "metadata": {
        "id": "Q6FxvISv3baz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 10, figsize = (20,10))\n",
        "for index, d in enumerate(data[np.random.choice(len(data), size = 10)]):\n",
        "    ax[index].imshow(data[index])\n",
        "    ax[index].axis('off')\n",
        "    ax[index].set_title(f'Label: {(labels[index])}')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "FRMXS60k3gaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CreateDataset(Dataset):\n",
        "  def __init__(self, data, labels):\n",
        "    self.data = torch.Tensor(data)\n",
        "    self.labels = torch.Tensor(labels)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        data_idx = self.data[idx]\n",
        "        label = self.labels[idx].type(torch.LongTensor)\n",
        "        return data_idx, label"
      ],
      "metadata": {
        "id": "nXi50uwj3jVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CreateDataset(data, labels)\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, (int(len(dataset)*0.8), len(dataset) - int(len(dataset)*0.8)))"
      ],
      "metadata": {
        "id": "g9F_4Hsj4K-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "trainloader = DataLoader(train_set, batch_size = batch_size)\n",
        "testloader = DataLoader(test_set, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "TFEJRdKy4eA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in trainloader:\n",
        "    print(f\"Shape of X: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    print(y)\n",
        "    break"
      ],
      "metadata": {
        "id": "gfBZL5ok50G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_stack = nn.Sequential(\n",
        "        nn.Linear(50 * 50, 100),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(100, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "UMZPw62J55iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "lossFN = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "NaaBpmVn63Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_dnn = []\n",
        "train_acc_dnn = []\n",
        "test_loss_dnn = []\n",
        "test_acc_dnn = []"
      ],
      "metadata": {
        "id": "E3dHUJdn6_eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, lossFN, optimizer, train_loss, train_acc):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.train()\n",
        "\n",
        "  running_loss, correct = 0, 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    pred = model(X)\n",
        "    loss = lossFN(pred, y)\n",
        "    train_loss.append(loss.item())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "\n",
        "    if(batch % batch_size == 0):\n",
        "      loss,current = loss.item(), batch*len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "  running_loss /= num_batches\n",
        "  correct /= size\n",
        "\n",
        "  train_acc.append(correct)\n",
        "  train_loss.append(running_loss)\n",
        "\n",
        "def test(dataloader,model,loss_fn,test_loss, test_acc):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  running_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "      for X,y in dataloader:\n",
        "          X,y = X.to(device), y.to(device)\n",
        "          pred = model(X)\n",
        "          running_loss += loss_fn(pred, y).item()\n",
        "          correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  running_loss /= num_batches\n",
        "  correct /= size\n",
        "\n",
        "  test_acc.append(correct)\n",
        "  test_loss.append(running_loss)\n",
        "  print(f\"Test Error: \\n Accuracy {(100*correct):>0.1f}%, Avg loss:{running_loss:>8f}\\n\")"
      ],
      "metadata": {
        "id": "B96tLaAA8DIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n -------------------\")\n",
        "    train(trainloader,model,lossFN,optimizer, train_loss_dnn, train_acc_dnn)\n",
        "    test(testloader,model,lossFN, test_loss_dnn, test_acc_dnn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "FUpV255z9qfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv_1st = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1)\n",
        "    self.conv_2nd = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1)\n",
        "    self.conv_3rd = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=7, stride=1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.seq = nn.Sequential(\n",
        "        nn.Linear(in_features=64 * 2 * 2, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=64, out_features=32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=32, out_features=2),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 1, 50, 50)\n",
        "    x = self.conv_1st(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.max_pool(x)\n",
        "    x = self.conv_2nd(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.max_pool(x)\n",
        "    x = self.conv_3rd(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.max_pool(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.seq(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "paMxYrYu94ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_cnn = []\n",
        "train_acc_cnn = []\n",
        "test_loss_cnn = []\n",
        "test_acc_cnn = []"
      ],
      "metadata": {
        "id": "IBE5-Y23B8f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "learning_rate = 1e-4\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f\"Epoch {epoch+1}\\n -------------------\")\n",
        "  train(trainloader, model, criterion, optimizer, train_loss_cnn, train_acc_cnn)\n",
        "  test(testloader, model, criterion, test_loss_cnn, test_acc_cnn)\n"
      ],
      "metadata": {
        "id": "xYpnMjCk_2Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_acc_loss_graph(train_acc,train_loss, test_acc, test_loss):\n",
        "    fig, axes = plt.subplots(ncols=2, nrows=1, dpi=300)\n",
        "    fig.set_size_inches(9, 3)\n",
        "    ax1, ax2 = axes[0], axes[1]\n",
        "\n",
        "    ax1.plot(train_acc,'-o',label=\"train\", markersize=4)\n",
        "    ax1.plot(test_acc,'--+',label=\"test\", markersize=4)\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend(loc=3)\n",
        "\n",
        "    ax2.plot(train_loss,'-o',label=\"train\", markersize=4)\n",
        "    ax2.plot(test_loss,'--+',label=\" test\", markersize=4)\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend(loc=1)\n",
        "\n",
        "    #plot parameters\n",
        "    ax1.set_ylim(0, np.max([np.max(train_acc),np.max(test_acc)])+0.1)\n",
        "    ax2.set_ylim(-0.1, np.max([np.max(train_loss),np.max(test_loss)])+0.1)\n",
        "    ax1.grid(True, which='both',linewidth=0.1)\n",
        "    ax2.grid(True, which='both',linewidth=0.1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cDrc5WT7CKNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_acc_loss_graph(train_acc_dnn,train_loss_dnn, test_acc_dnn, test_loss_dnn)\n",
        "create_acc_loss_graph(train_acc_cnn,train_loss_cnn, test_acc_cnn, test_acc_cnn)"
      ],
      "metadata": {
        "id": "Rh57b3M9GtwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42X9wFw3G5Zs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}